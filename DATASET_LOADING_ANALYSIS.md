# ë°ì´í„°ì…‹ ë¡œë”© ì‹¬ì¸µ ë¶„ì„ (Dataset Loading Deep Dive)

## ğŸ“‹ ëª©ì°¨
1. [ì „ì²´ êµ¬ì¡° ê°œìš”](#ì „ì²´-êµ¬ì¡°-ê°œìš”)
2. [ë°ì´í„°ì…‹ ë“±ë¡ í”Œë¡œìš°](#ë°ì´í„°ì…‹-ë“±ë¡-í”Œë¡œìš°)
3. [ë°ì´í„°ì…‹ íƒ€ì…ë³„ ìƒì„¸ ë¶„ì„](#ë°ì´í„°ì…‹-íƒ€ì…ë³„-ìƒì„¸-ë¶„ì„)
4. [ë°ì´í„° ë¡œë”© ë©”ì»¤ë‹ˆì¦˜](#ë°ì´í„°-ë¡œë”©-ë©”ì»¤ë‹ˆì¦˜)
5. [ìºì‹± ì‹œìŠ¤í…œ](#ìºì‹±-ì‹œìŠ¤í…œ)
6. [ë°ì´í„° ë³€í™˜ ê³¼ì •](#ë°ì´í„°-ë³€í™˜-ê³¼ì •)
7. [ë©€í‹° ë°ì´í„°ì…‹ ì²˜ë¦¬](#ë©€í‹°-ë°ì´í„°ì…‹-ì²˜ë¦¬)

---

## ì „ì²´ êµ¬ì¡° ê°œìš”

```
train_iterative_model.py (ë©”ì¸ ì—”íŠ¸ë¦¬)
    â†“
register_datasets(cfg) [data/tools/utils.py]
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DATASETS.TYPEì— ë”°ë¥¸ ë¶„ê¸°              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ VISUAL GENOME                        â”‚
â”‚  â€¢ SYNTHETIC GENOME                     â”‚
â”‚  â€¢ MULTI_DATASET                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
ê° ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì´ˆê¸°í™”
    â†“
_fetch_data_dict() â†’ pickle ìºì‹œ í™•ì¸
    â†“
_process_data() â†’ H5 íŒŒì¼ ì½ê¸°
    â†“
_load_graphs() â†’ Detectron2 í˜•ì‹ ë³€í™˜
    â†“
DatasetCatalog.register() â†’ Detectron2ì— ë“±ë¡
    â†“
DetrDatasetMapper â†’ í•™ìŠµ/ì¶”ë¡  ì‹œ ë³€í™˜
```

---

## ë°ì´í„°ì…‹ ë“±ë¡ í”Œë¡œìš°

### 1. ì´ˆê¸°í™” ì§€ì 

**íŒŒì¼**: `train_iterative_model.py`

```python
def setup(args):
    cfg = get_cfg()
    add_dataset_config(cfg)
    add_scenegraph_config(cfg)
    cfg.merge_from_file(args.config_file)
    cfg.merge_from_list(args.opts)
    cfg.freeze()
    register_datasets(cfg)  # â† ì—¬ê¸°ì„œ ë°ì´í„°ì…‹ ë“±ë¡
    default_setup(cfg, args)
    return cfg
```

### 2. ë“±ë¡ í•¨ìˆ˜

**íŒŒì¼**: `data/tools/utils.py`

```python
def register_datasets(cfg):
    if cfg.DATASETS.TYPE == 'VISUAL GENOME':
        for split in ['train', 'val', 'test']:
            dataset_instance = VisualGenomeTrainData(cfg, split=split)
    elif cfg.DATASETS.TYPE == 'SYNTHETIC GENOME':
        for split in ['train', 'val', 'test']:
            dataset_instance = SyntheticGenomeTrainData(cfg, split=split)
    elif cfg.DATASETS.TYPE == 'MULTI_DATASET':
        register_multi_datasets(cfg)
    else:
        raise ValueError(f"Unsupported dataset type: {cfg.DATASETS.TYPE}")
```

---

## ë°ì´í„°ì…‹ íƒ€ì…ë³„ ìƒì„¸ ë¶„ì„

### 1. VisualGenomeTrainData

**íŒŒì¼**: `data/datasets/visual_genome.py`

#### ì£¼ìš” êµ¬ì„± ìš”ì†Œ

```python
class VisualGenomeTrainData:
    def __init__(self, cfg, split='train'):
        # 1. ì„¤ì • ë¡œë“œ
        self.cfg = cfg
        self.split = split
        
        # 2. ë§ˆìŠ¤í¬ íŒŒì¼ ê²½ë¡œ ì„¤ì •
        if split == 'train':
            self.mask_location = cfg.DATASETS.VISUAL_GENOME.TRAIN_MASKS
        elif split == 'val':
            self.mask_location = cfg.DATASETS.VISUAL_GENOME.VAL_MASKS
        else:
            self.mask_location = cfg.DATASETS.VISUAL_GENOME.TEST_MASKS
        
        # 3. í•„í„°ë§ ì˜µì…˜
        self.filter_empty_relations = cfg.DATASETS.VISUAL_GENOME.FILTER_EMPTY_RELATIONS
        self.filter_non_overlap = cfg.DATASETS.VISUAL_GENOME.FILTER_NON_OVERLAP
        
        # 4. ë°ì´í„° ë¡œë“œ (ìºì‹œ ìš°ì„ )
        self.dataset_dicts = self._fetch_data_dict()
        
        # 5. Detectron2ì— ë“±ë¡
        self.register_dataset()
        
        # 6. í†µê³„ ì •ë³´ ê³„ì‚°
        statistics = self.get_statistics()
```

#### ë°ì´í„° ì†ŒìŠ¤

1. **H5 íŒŒì¼**: `VG_ATTRIBUTE_H5`
   - ì´ë¯¸ì§€ë³„ ë°•ìŠ¤, ë¼ë²¨, ê´€ê³„ ì •ë³´
   - êµ¬ì¡°:
     ```
     'split': [0=train, 1=val, 2=test]
     'img_to_first_box': ì´ë¯¸ì§€ë³„ ì²« ë°•ìŠ¤ ì¸ë±ìŠ¤
     'img_to_last_box': ì´ë¯¸ì§€ë³„ ë§ˆì§€ë§‰ ë°•ìŠ¤ ì¸ë±ìŠ¤
     'img_to_first_rel': ì´ë¯¸ì§€ë³„ ì²« ê´€ê³„ ì¸ë±ìŠ¤
     'img_to_last_rel': ì´ë¯¸ì§€ë³„ ë§ˆì§€ë§‰ ê´€ê³„ ì¸ë±ìŠ¤
     'boxes_1024': [N, 4] (cx, cy, w, h) í˜•ì‹
     'labels': [N] ê°ì²´ í´ë˜ìŠ¤
     'attributes': [N, K] ê°ì²´ ì†ì„±
     'relationships': [M, 2] (subject_idx, object_idx)
     'predicates': [M] ê´€ê³„ íƒ€ì…
     ```

2. **JSON íŒŒì¼**: 
   - `MAPPING_DICTIONARY`: í´ë˜ìŠ¤/ì†ì„±/ê´€ê³„ ë§¤í•‘
   - `IMAGE_DATA`: ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° (ì´ë¯¸ì§€ ID, í¬ê¸° ë“±)

#### ë°ì´í„° êµ¬ì¡° ë³€í™˜

**H5 í˜•ì‹** â†’ **Detectron2 í˜•ì‹**

```python
record = {
    'file_name': '/path/to/image.jpg',
    'image_id': 12345,
    'height': 768,
    'width': 1024,
    'annotations': [
        {
            'bbox': [x1, y1, x2, y2],
            'bbox_mode': BoxMode.XYXY_ABS,
            'category_id': 0,  # 0-indexed
            'attribute': [1, 0, 1, ...],  # ì†ì„± ë²¡í„°
            'segmentation': [...]  # optional
        },
        ...
    ],
    'relations': np.array([
        [subject_idx, object_idx, predicate_idx],
        ...
    ])  # shape: [N, 3]
}
```

### 2. SyntheticGenomeTrainData

**íŒŒì¼**: `data/datasets/synthetic_genome.py`

VisualGenomeTrainDataì™€ ê±°ì˜ ë™ì¼í•˜ì§€ë§Œ:
- ë‹¤ë¥¸ H5 íŒŒì¼ ê²½ë¡œ ì‚¬ìš© (`SYNTHETIC_ATTRIBUTE_H5`)
- ë‹¤ë¥¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì‚¬ìš©
- ë³„ë„ì˜ ì´ë¯¸ì§€ ì œê±° ë¦¬ìŠ¤íŠ¸ (`synthetic_images_to_remove.txt`)

### 3. MultiDatasetTrainData

**íŒŒì¼**: `data/datasets/multi_dataset.py`

#### í•µì‹¬ íŠ¹ì§•

1. **ë‘ ë°ì´í„°ì…‹ ë™ì‹œ ë¡œë“œ**
   ```python
   # Real dataset
   real_cfg = copy.deepcopy(cfg)
   real_cfg.DATASETS.TYPE = "VISUAL GENOME"
   real_dataset = VisualGenomeTrainData(real_cfg, split=split)
   
   # Synthetic dataset
   synthetic_cfg = copy.deepcopy(cfg)
   synthetic_cfg.DATASETS.TYPE = "VISUAL GENOME"
   synthetic_cfg.DATASETS.VISUAL_GENOME = cfg.DATASETS.VISUAL_GENOME_SYNTHETIC
   synthetic_dataset = VisualGenomeTrainData(synthetic_cfg, split=split)
   ```

2. **ë™ì  ìƒ˜í”Œë§**
   - `MultiDatasetDynamicSampler` ì‚¬ìš©
   - ë°°ì¹˜ ë‹¨ìœ„ë¡œ real/synthetic ë¹„ìœ¨ ìœ ì§€
   - ì˜ˆ: real 70%, synthetic 30%

3. **í†µê³„ ì •ë³´ ê²°í•©**
   ```python
   def get_statistics(self):
       real_stats = self.real_dataset.get_statistics()
       synthetic_stats = self.synthetic_dataset.get_statistics()
       
       # í†µê³„ í•©ì‚°
       combined_fg_rel_count = real_stats['fg_rel_count'] + synthetic_stats['fg_rel_count']
       combined_fg_matrix = real_stats['fg_matrix'] + synthetic_stats['fg_matrix']
       combined_pred_dist = torch.log(combined_fg_matrix / ...)
       
       return combined_statistics
   ```

---

## ë°ì´í„° ë¡œë”© ë©”ì»¤ë‹ˆì¦˜

### 1. ìºì‹œ ê¸°ë°˜ ë¡œë”©

**íŒŒì¼**: `data/datasets/visual_genome.py::_fetch_data_dict()`

```python
def _fetch_data_dict(self):
    # ìºì‹œ íŒŒì¼ëª… ìƒì„± (ì„¤ì •ì— ë”°ë¼ ë‹¤ë¦„)
    fileName = "tmp/visual_genome_{}_data_{}{}{}{}{}{}{}{}_{}.pkl".format(
        self.split, 
        'masks' if self.mask_exists else '', 
        '_oi' if 'oi' in self.mask_location else '', 
        "_clamped" if self.clamped else "", 
        "_precomp" if self.precompute else "", 
        "_clipped" if self.clipped else "", 
        '_overlapfalse' if not self.cfg.DATASETS.VISUAL_GENOME.FILTER_NON_OVERLAP else "", 
        '_emptyfalse' if not self.cfg.DATASETS.VISUAL_GENOME.FILTER_EMPTY_RELATIONS else '', 
        "_perclass" if self.per_class_dataset else '',
        h5_path_hash  # H5 íŒŒì¼ ê²½ë¡œ í•´ì‹œ (ì¤‘ìš”!)
    )
    
    if os.path.isfile(fileName):
        # ìºì‹œì—ì„œ ë¡œë“œ
        with open(fileName, 'rb') as inputFile:
            dataset_dicts = pickle.load(inputFile)
    else:
        # ì²˜ìŒ ë¡œë“œ - ì²˜ë¦¬ í›„ ìºì‹œ ì €ì¥
        os.makedirs('tmp', exist_ok=True)
        dataset_dicts = self._process_data()
        with open(fileName, 'wb') as inputFile:
            pickle.dump(dataset_dicts, inputFile)
    
    return dataset_dicts
```

**ìºì‹œ íŒŒì¼ëª… ì˜ˆì‹œ**:
```
tmp/visual_genome_train_data__overlapfalse_a6814dad.pkl
```

### 2. H5 íŒŒì¼ ì²˜ë¦¬

**íŒŒì¼**: `data/datasets/visual_genome.py::_process_data()`

```python
def _process_data(self):
    # 1. H5 íŒŒì¼ ì˜¤í”ˆ
    self.VG_attribute_h5 = h5py.File(
        self.cfg.DATASETS.VISUAL_GENOME.VG_ATTRIBUTE_H5, 'r'
    )
    
    # 2. ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ë¡œë“œ
    image_data = json.load(open(self.cfg.DATASETS.VISUAL_GENOME.IMAGE_DATA, 'r'))
    
    # 3. ì†ìƒëœ ì´ë¯¸ì§€ ì œê±°
    self.corrupted_ims = ['1592', '1722', '4616', '4617']
    for img in image_data:
        if str(img['image_id']) in self.corrupted_ims:
            continue
        self.image_data.append(img)
    
    # 4. ë§ˆìŠ¤í¬ ë¡œë“œ (ì˜µì…˜)
    if self.mask_location != "":
        with open(self.mask_location, 'rb') as f:
            self.masks = pickle.load(f)
    
    # 5. ê·¸ë˜í”„ ë°ì´í„° ë¡œë“œ
    dataset_dicts = self._load_graphs()
    return dataset_dicts
```

### 3. ê·¸ë˜í”„ ë°ì´í„° ë³€í™˜

**íŒŒì¼**: `data/datasets/visual_genome.py::_load_graphs()`

#### ë‹¨ê³„ë³„ ì²˜ë¦¬

```python
def _load_graphs(self):
    # 1. Split í•„í„°ë§
    data_split = self.VG_attribute_h5['split'][:]
    split_flag = 0 if self.split == 'train' else 1 if self.split == 'val' else 2
    split_mask = data_split == split_flag
    
    # 2. ë°•ìŠ¤ê°€ ì—†ëŠ” ì´ë¯¸ì§€ í•„í„°ë§
    split_mask &= self.VG_attribute_h5['img_to_first_box'][:] >= 0
    
    # 3. ê´€ê³„ê°€ ì—†ëŠ” ì´ë¯¸ì§€ í•„í„°ë§ (ì˜µì…˜)
    if self.cfg.DATASETS.VISUAL_GENOME.FILTER_EMPTY_RELATIONS:
        split_mask &= self.VG_attribute_h5['img_to_first_rel'][:] >= 0
    
    image_index = np.where(split_mask)[0]
    
    # 4. ëª¨ë“  ë°ì´í„° ë¡œë“œ
    all_labels = self.VG_attribute_h5['labels'][:, 0]
    all_attributes = self.VG_attribute_h5['attributes'][:, :]
    all_boxes = self.VG_attribute_h5['boxes_1024'][:]  # cx, cy, w, h
    
    # 5. ë°•ìŠ¤ í˜•ì‹ ë³€í™˜: (cx, cy, w, h) â†’ (x1, y1, x2, y2)
    all_boxes[:, :2] = all_boxes[:, :2] - all_boxes[:, 2:] / 2
    all_boxes[:, 2:] = all_boxes[:, :2] + all_boxes[:, 2:]
    
    # 6. ì´ë¯¸ì§€ë³„ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    first_box_index = self.VG_attribute_h5['img_to_first_box'][split_mask]
    last_box_index = self.VG_attribute_h5['img_to_last_box'][split_mask]
    first_relation_index = self.VG_attribute_h5['img_to_first_rel'][split_mask]
    last_relation_index = self.VG_attribute_h5['img_to_last_rel'][split_mask]
    
    # 7. ê´€ê³„ ë°ì´í„°
    all_relations = self.VG_attribute_h5['relationships'][:]
    all_relation_predicates = self.VG_attribute_h5['predicates'][:, 0]
    
    # 8. ì´ë¯¸ì§€ë³„ë¡œ ë°˜ë³µí•˜ì—¬ record ìƒì„±
    dataset_dicts = []
    for idx, _ in enumerate(image_index):
        record = {}
        
        # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°
        image_data = self.image_data[image_indexer[idx]]
        record['file_name'] = os.path.join(
            self.cfg.DATASETS.VISUAL_GENOME.IMAGES, 
            '{}.jpg'.format(image_data['image_id'])
        )
        record['image_id'] = image_data['image_id']
        record['height'] = image_data['height']
        record['width'] = image_data['width']
        
        # ë°•ìŠ¤ ë° ë¼ë²¨
        boxes = all_boxes[first_box_index[idx]:last_box_index[idx] + 1, :]
        gt_classes = all_labels[first_box_index[idx]:last_box_index[idx] + 1]
        gt_attributes = all_attributes[first_box_index[idx]:last_box_index[idx] + 1, :]
        
        # ê´€ê³„
        if first_relation_index[idx] > -1:
            predicates = all_relation_predicates[
                first_relation_index[idx]:last_relation_index[idx] + 1
            ]
            objects = all_relations[
                first_relation_index[idx]:last_relation_index[idx] + 1
            ] - first_box_index[idx]  # ì´ë¯¸ì§€ ë‚´ ìƒëŒ€ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
            predicates = predicates - 1  # 1-indexed â†’ 0-indexed
            relations = np.column_stack((objects, predicates))
        else:
            relations = np.zeros((0, 3), dtype=np.int32)
        
        # í•„í„°ë§: ê²¹ì¹˜ì§€ ì•ŠëŠ” ê´€ê³„ ì œê±° (ì˜µì…˜)
        if self.cfg.DATASETS.VISUAL_GENOME.FILTER_NON_OVERLAP and self.split == 'train':
            boxes_list = Boxes(boxes)
            ious = pairwise_iou(boxes_list, boxes_list)
            relation_boxes_ious = ious[relations[:,0], relations[:,1]]
            iou_indexes = np.where(relation_boxes_ious > 0.0)[0]
            if iou_indexes.size > 0:
                relations = relations[iou_indexes]
            else:
                continue  # ì´ë¯¸ì§€ ê±´ë„ˆë›°ê¸°
        
        # ê°ì²´ ì–´ë…¸í…Œì´ì…˜ ìƒì„±
        objects = []
        for obj_idx in range(len(boxes)):
            # ë°•ìŠ¤ í¬ê¸° ì¡°ì • (BOX_SCALE ê¸°ì¤€)
            resized_box = boxes[obj_idx] / self.cfg.DATASETS.VISUAL_GENOME.BOX_SCALE * max(
                record['height'], record['width']
            )
            obj = {
                "bbox": resized_box.tolist(),
                "bbox_mode": BoxMode.XYXY_ABS,
                "category_id": gt_classes[obj_idx] - 1,  # 1-indexed â†’ 0-indexed
                "attribute": gt_attributes[obj_idx],
            }
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ (ì˜µì…˜)
            if self.masks is not None:
                gt_masks = self.masks[image_data['image_id']]
                if gt_masks['empty_index'][obj_idx]:
                    refined_poly = []
                    for poly in gt_masks['polygons'][mask_idx]:
                        if len(poly) >= 6:  # ìµœì†Œ í¬ì¸íŠ¸ ìˆ˜
                            refined_poly.append(poly)
                    obj["segmentation"] = refined_poly
                    mask_idx += 1
                else:
                    obj["segmentation"] = []
            
            objects.append(obj)
        
        record['annotations'] = objects
        record['relations'] = relations
        dataset_dicts.append(record)
    
    return dataset_dicts
```

---

## ìºì‹± ì‹œìŠ¤í…œ

### ìºì‹œ íŒŒì¼ëª… ìƒì„± ê·œì¹™

ìºì‹œ íŒŒì¼ëª…ì€ ë‹¤ìŒ íŒŒë¼ë¯¸í„°ë“¤ì„ ì¡°í•©í•˜ì—¬ ìƒì„±ë©ë‹ˆë‹¤:

1. **ê¸°ë³¸ ì •ë³´**: `visual_genome_{split}_data_`
2. **ë§ˆìŠ¤í¬ ì¡´ì¬ ì—¬ë¶€**: `masks` (ìˆìœ¼ë©´)
3. **ë§ˆìŠ¤í¬ íƒ€ì…**: `_oi` (OI í¬í•¨ ì‹œ)
4. **Clamped ì—¬ë¶€**: `_clamped`
5. **Precompute ì—¬ë¶€**: `_precomp`
6. **Clipped ì—¬ë¶€**: `_clipped`
7. **Overlap í•„í„°**: `_overlapfalse` (í•„í„°ë§ ì•ˆ í•¨)
8. **Empty ê´€ê³„ í•„í„°**: `_emptyfalse` (í•„í„°ë§ ì•ˆ í•¨)
9. **Per-class ìƒ˜í”Œë§**: `_perclass`
10. **H5 íŒŒì¼ ê²½ë¡œ í•´ì‹œ**: `_{h5_path_hash}` âš ï¸ **ì¤‘ìš”**

### ìºì‹œ ë¬´íš¨í™”

H5 íŒŒì¼ ê²½ë¡œê°€ ë³€ê²½ë˜ë©´ í•´ì‹œê°€ ë‹¬ë¼ì ¸ ìë™ìœ¼ë¡œ ìƒˆ ìºì‹œê°€ ìƒì„±ë©ë‹ˆë‹¤.

---

## ë°ì´í„° ë³€í™˜ ê³¼ì •

### 1. DatasetMapper

**íŒŒì¼**: `data/dataset_mapper.py::DetrDatasetMapper`

#### ì—­í• 

Detectron2 í˜•ì‹ì˜ dict â†’ ëª¨ë¸ ì…ë ¥ í˜•ì‹

#### ì£¼ìš” ë³€í™˜

```python
def __call__(self, dataset_dict):
    # 1. ì´ë¯¸ì§€ ë¡œë“œ ë° ë³€í™˜
    image = utils.read_image(dataset_dict["file_name"], format=self.img_format)
    
    # 2. ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    image, transforms = T.apply_transform_gens(self.tfm_gens, image)
    
    # 3. í…ì„œ ë³€í™˜
    dataset_dict["image"] = torch.as_tensor(
        np.ascontiguousarray(image.transpose(2, 0, 1))
    )
    
    # 4. ì¤‘ë³µ ê´€ê³„ í•„í„°ë§ (ì˜µì…˜)
    if self.filter_duplicate_relations and self.is_train:
        relation_dict = defaultdict(list)
        for object_0, object_1, relation in dataset_dict["relations"]:
            relation_dict[(object_0,object_1)].append(relation)
        dataset_dict["relations"] = [
            (k[0], k[1], np.random.choice(v)) 
            for k,v in relation_dict.items()
        ]
    
    # 5. ì–´ë…¸í…Œì´ì…˜ ë³€í™˜
    annos = [
        utils.transform_instance_annotations(obj, transforms, image_shape)
        for obj in dataset_dict.pop("annotations")
        if obj.get("iscrowd", 0) == 0
    ]
    instances = utils.annotations_to_instances(annos, image_shape)
    
    # 6. ì†ì„± ì¶”ê°€
    attributes = [obj['attribute'] for obj in annos]
    instances.gt_attributes = torch.from_numpy(np.array(attributes, dtype=np.int64))
    
    # 7. ë¹ˆ ì¸ìŠ¤í„´ìŠ¤ í•„í„°ë§
    dataset_dict["instances"], filter_mask = utils.filter_empty_instances(
        instances, return_mask=True
    )
    
    # 8. ê´€ê³„ ì¸ë±ìŠ¤ ì¬ë§¤í•‘ (í•„í„°ë§ëœ ê°ì²´ ë°˜ì˜)
    if not filter_mask.all():
        object_mapper = {
            int(old_idx): new_idx 
            for new_idx, old_idx in enumerate(torch.arange(filter_mask.size(0))[filter_mask])
        }
        new_relations = []
        for object_0, object_1, relation in dataset_dict['relations'].numpy():
            if (object_0 in object_mapper) and (object_1 in object_mapper):
                new_relations.append([
                    object_mapper[object_0], 
                    object_mapper[object_1], 
                    relation
                ])
        dataset_dict['relations'] = torch.tensor(new_relations) if new_relations else torch.zeros(0, 3).long()
    
    # 9. ìµœëŒ€ ê°ì²´/ê´€ê³„ ìˆ˜ ì œí•œ (ì˜µì…˜)
    if len(dataset_dict['instances']) > self.max_num_objs:
        sample_idxs = np.random.permutation(
            np.arange(len(dataset_dict['instances']))
        )[:self.max_num_objs]
        dataset_dict['instances'] = dataset_dict['instances'][sample_idxs]
        # ê´€ê³„ ì¬ë§¤í•‘...
    
    return dataset_dict
```

---

## ë©€í‹° ë°ì´í„°ì…‹ ì²˜ë¦¬

### MultiDatasetDynamicSampler

**íŒŒì¼**: `data/datasets/multi_dataset.py`

#### ë™ì‘ ì›ë¦¬

```python
class MultiDatasetDynamicSampler(Dataset):
    def __init__(self, real_dicts, synthetic_dicts, 
                 real_ratio=0.7, synthetic_ratio=0.3,
                 real_loss_weight=1.0, synthetic_loss_weight=0.5,
                 batch_size=10):
        self.real_dicts = real_dicts
        self.synthetic_dicts = synthetic_dicts
        self.real_ratio = real_ratio
        self.synthetic_ratio = synthetic_ratio
        self.real_loss_weight = real_loss_weight
        self.synthetic_loss_weight = synthetic_loss_weight
        self.batch_size = batch_size
        
        # ë°°ì¹˜ë‹¹ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
        self.real_samples_per_batch = int(batch_size * real_ratio)
        self.synthetic_samples_per_batch = batch_size - self.real_samples_per_batch
        
        # ì „ì²´ í¬ê¸° ê³„ì‚°
        min_size = min(len(real_dicts), len(synthetic_dicts))
        self.total_size = int(min_size / min(real_ratio, synthetic_ratio))
    
    def __getitem__(self, idx):
        # ë°°ì¹˜ ì¸ë±ìŠ¤ì™€ ë°°ì¹˜ ë‚´ ìœ„ì¹˜ ê³„ì‚°
        batch_idx = idx // self.batch_size
        item_idx = idx % self.batch_size
        
        # ë°°ì¹˜ ìœ„ì¹˜ì— ë”°ë¼ real/synthetic ì„ íƒ
        if item_idx < self.real_samples_per_batch:
            # Real ë°ì´í„°ì…‹ì—ì„œ ìƒ˜í”Œë§
            real_idx = np.random.randint(0, len(self.real_dicts))
            item = copy.deepcopy(self.real_dicts[real_idx])
            item['dataset_type'] = 'real'
            item['loss_weight'] = self.real_loss_weight
        else:
            # Synthetic ë°ì´í„°ì…‹ì—ì„œ ìƒ˜í”Œë§
            synthetic_idx = np.random.randint(0, len(self.synthetic_dicts))
            item = copy.deepcopy(self.synthetic_dicts[synthetic_idx])
            item['dataset_type'] = 'synthetic'
            item['loss_weight'] = self.synthetic_loss_weight
        
        return item
```

#### íŠ¹ì§•

1. **ë°°ì¹˜ ë‹¨ìœ„ ë¹„ìœ¨ ë³´ì¥**: ê° ë°°ì¹˜ì—ì„œ ì •í™•í•œ ë¹„ìœ¨ ìœ ì§€
2. **ëœë¤ ìƒ˜í”Œë§**: ë§¤ë²ˆ ëœë¤í•˜ê²Œ ì„ íƒí•˜ì—¬ ë‹¤ì–‘ì„± í™•ë³´
3. **Loss ê°€ì¤‘ì¹˜**: ë°ì´í„°ì…‹ íƒ€ì…ë³„ë¡œ ë‹¤ë¥¸ loss ê°€ì¤‘ì¹˜ ì ìš©
4. **ë©”íƒ€ë°ì´í„° ì¶”ê°€**: `dataset_type`, `loss_weight` í•„ë“œ ì¶”ê°€

---

## ì£¼ìš” ì„¤ì • íŒŒë¼ë¯¸í„°

### Visual Genome ì„¤ì •

```yaml
DATASETS:
  VISUAL_GENOME:
    IMAGES: '/path/to/images'
    MAPPING_DICTIONARY: '/path/to/mapping.json'
    IMAGE_DATA: '/path/to/image_data.json'
    VG_ATTRIBUTE_H5: '/path/to/data.h5'
    TRAIN_MASKS: ""  # ë§ˆìŠ¤í¬ íŒŒì¼ ê²½ë¡œ (ì˜µì…˜)
    FILTER_EMPTY_RELATIONS: True
    FILTER_NON_OVERLAP: False
    FILTER_DUPLICATE_RELATIONS: True
    BOX_SCALE: 1024
    MAX_NUM_RELATIONS: -1  # -1 = ë¬´ì œí•œ
    MAX_NUM_OBJECTS: -1
```

### Multi-Dataset ì„¤ì •

```yaml
DATASETS:
  TYPE: "MULTI_DATASET"
  MULTI_DATASET:
    ENABLED: True
    REAL_SAMPLING_RATIO: 0.7
    SYNTHETIC_SAMPLING_RATIO: 0.3
    REAL_LOSS_WEIGHT: 1.0
    SYNTHETIC_LOSS_WEIGHT: 0.5
```

---

## ì„±ëŠ¥ ìµœì í™” í¬ì¸íŠ¸

### 1. ìºì‹± í™œìš©

- ì²« ë¡œë“œ ì‹œ pickleë¡œ ì €ì¥
- ì„¤ì • ë³€ê²½ ì‹œì—ë§Œ ì¬ì²˜ë¦¬ í•„ìš”
- H5 íŒŒì¼ ê²½ë¡œ í•´ì‹œë¡œ ìë™ ë¬´íš¨í™”

### 2. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±

- H5 íŒŒì¼ì€ ë©”ëª¨ë¦¬ì— ì „ì²´ ë¡œë“œ
- ì´ë¯¸ì§€ íŒŒì¼ì€ í•„ìš” ì‹œì—ë§Œ ë¡œë“œ (DatasetMapperì—ì„œ)
- ê´€ê³„ ë°ì´í„°ëŠ” ìŠ¤íŒŒìŠ¤ ì¸ë±ì‹±ìœ¼ë¡œ ì ‘ê·¼

### 3. ë³‘ë ¬ ì²˜ë¦¬

- `DATALOADER.NUM_WORKERS` ì„¤ì •ìœ¼ë¡œ ë©€í‹°í”„ë¡œì„¸ì‹±
- ê° ì›Œì»¤ê°€ ë…ë¦½ì ìœ¼ë¡œ ë°ì´í„° ë¡œë“œ

---

## ë””ë²„ê¹… íŒ

### 1. ìºì‹œ í™•ì¸

```python
import os
cache_files = [f for f in os.listdir('tmp/') if f.startswith('visual_genome')]
print(cache_files)
```

### 2. ë°ì´í„°ì…‹ í¬ê¸° í™•ì¸

```python
from detectron2.data import DatasetCatalog
dataset_dicts = DatasetCatalog.get('VG_train')
print(f"Dataset size: {len(dataset_dicts)}")
print(f"First sample keys: {dataset_dicts[0].keys()}")
```

### 3. í†µê³„ ì •ë³´ í™•ì¸

```python
from detectron2.data import MetadataCatalog
metadata = MetadataCatalog.get('VG_train')
if hasattr(metadata, 'statistics'):
    print(f"Object classes: {len(metadata.thing_classes)}")
    print(f"Predicate classes: {len(metadata.predicate_classes)}")
    print(f"Relation count: {metadata.statistics['fg_rel_count'].sum()}")
```

### 4. H5 íŒŒì¼ êµ¬ì¡° í™•ì¸

```python
import h5py
with h5py.File('VG-SGG-with-attri.h5', 'r') as f:
    print("Keys:", list(f.keys()))
    print("Split shape:", f['split'].shape)
    print("Labels shape:", f['labels'].shape)
```

---

## ì£¼ì˜ì‚¬í•­

1. **ì¸ë±ì‹± ë³€í™˜**: H5 íŒŒì¼ì€ 1-indexed, Detectron2ëŠ” 0-indexed
2. **ë°•ìŠ¤ í˜•ì‹ ë³€í™˜**: (cx, cy, w, h) â†’ (x1, y1, x2, y2)
3. **ê´€ê³„ ì¸ë±ìŠ¤**: í•„í„°ë§ í›„ ê°ì²´ ì¸ë±ìŠ¤ ì¬ë§¤í•‘ í•„ìš”
4. **ìºì‹œ ë¬´íš¨í™”**: H5 íŒŒì¼ ë³€ê²½ ì‹œ ìºì‹œ íŒŒì¼ ì‚­ì œ ë˜ëŠ” ìë™ ë¬´íš¨í™”
5. **ë©”ëª¨ë¦¬**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì˜ ê²½ìš° ë©”ëª¨ë¦¬ ë¶€ì¡± ì£¼ì˜

---

## ê´€ë ¨ íŒŒì¼ ëª©ë¡

- `data/tools/utils.py`: ë°ì´í„°ì…‹ ë“±ë¡
- `data/datasets/visual_genome.py`: Visual Genome ë°ì´í„°ì…‹
- `data/datasets/synthetic_genome.py`: Synthetic ë°ì´í„°ì…‹
- `data/datasets/multi_dataset.py`: ë©€í‹° ë°ì´í„°ì…‹ ì²˜ë¦¬
- `data/dataset_mapper.py`: ë°ì´í„° ë³€í™˜
- `configs/defaults.py`: ê¸°ë³¸ ì„¤ì •
- `train_iterative_model.py`: í•™ìŠµ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸

